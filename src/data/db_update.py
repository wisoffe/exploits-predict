"""
/src/data/db_update.py script for download and update internal database.
Designed for daily scheduled launch via github actions.

Gets data from the following sources:
- api vulners.com (exploits);
- api services.nvd.nist.gov (cve).

Update tables:
- cve
- exploit
- cve_exploit
- dbupdate_stats
"""

import os
import requests
import json
import re
from dateutil.parser import parse
from time import sleep
from datetime import datetime, timedelta
from dotenv import load_dotenv
from src.db import InternalDB
from src.log_stats import RunStatsDBUpdate

load_dotenv()  # env existing in the system are not overwritten

# vulners.com api key (a free key may not be enough due
# to a limit of 100 requests per month, the project uses a research license)
VULNERS_API_PARAMS = {"api_key": os.environ.get("VULNERS_API_KEY")}
        
        
def vulners_api_request(*args, **kwargs):
    """Request to vulners.com api with check for correct response.
    Raise exceptions for bad responses."""

    req = requests.get(*args, **kwargs)

    if req.status_code != requests.codes.ok:
        raise Exception(f"Bad api status code: {req.status_code}")

    if req.json()["result"] != "OK":
        raise Exception(f"Bad api result: {req.json()}")

    return req


def get_last_modified_from_db(db, family):
    relevant_fields = {
        "cve": "cve_lastModified",
        "exploit": "exploit_modified",
    }
    assert family in relevant_fields

    sql_query = f"""
    SELECT MAX({relevant_fields[family]}) FROM dbupdate_stats;
    """
    return parse(db.safe_read_query(sql_query)[0][0])


def get_raw_exploit_updates_from_api(exp_last_db_modified, max_records_threashold=10_000):
    """Getting the latest updates from api on exploits, returns raw
    data without processing.

    exp_last_db_modified (datetime): date of last update of exploits
        in the database
    max_records_threashold (positive int or 0 for no limit): the threshold
        for the maximum number of records from the api, if we exceed it, most
        likely something is going wrong (should be significantly more than
        the typical number of updates that we expect to receive since the last
        update); necessary in order not to spend all the license tokens for api

    Returns: list of exploit dicts.
    """
    URL_VULNERS_SEARCH_API = "https://vulners.com/api/v3/search/lucene/?"
    query = "bulletinFamily:exploit AND order:modified".replace(" ", "%20")

    exploits_raw_list = []
    complete_flag = False
    total_records = None
    search_size = 100  # maximum allowed number of records per request (api limit)
    skip = 0

    while total_records is None or skip < total_records:
        if max_records_threashold and skip > max_records_threashold:
            raise Exception(f"Attempt to download too many records: {skip}")

        req = vulners_api_request(
            f"{URL_VULNERS_SEARCH_API}query={query}&size={search_size}&skip={skip}",
            params=VULNERS_API_PARAMS,
        )
        # only for first request
        if total_records is None:
            total_records = req.json()["data"]["total"]
            print("Getting records from vulners api:", end="")

        items_list = req.json()["data"]["search"]

        print(f" +{len(items_list)}", end="")

        for item in items_list:
            # consciously (>= instead of >) pump out with a margin (1-2 pcs.)
            if parse(item["_source"]["modified"]) >= exp_last_db_modified:
                exploits_raw_list.append(item)
            else:
                complete_flag = True
                break

        if complete_flag:
            break

        skip += search_size
        sleep(3)

    print(f"\nSuccessful downloaded: {len(exploits_raw_list)} exploits.")

    return exploits_raw_list


def normalize_cve_list(cve_list: list) -> list:
    """
    Нормализует список CVE:
     - приводит '1999-0021' к 'CVE-1999-0021'
     - приводит 'CVE2014-1303' к 'CVE-2014-1303'
     - приводит 'CVE-2017-18344.' к 'CVE-2017-18344'
     - по итогу удаляет дубликаты
    """
    cve_set_correct = set()
    for cve in cve_list:
        if cve[-1] == ".":
            cve = cve[:-1]
        if cve.startswith("CVE-"):
            cve_set_correct.add(cve)
        elif cve.startswith("CVE"):
            cve_set_correct.add("CVE-" + cve[3:])
        else:
            cve_set_correct.add("CVE-" + cve)
    return list(cve_set_correct)


def normalize_cve_list_of_lists(cve_lists: list) -> list:
    """
    Нормализует каждое CVE в списке из списков CVE.
    See normalized patterns in normalize_cve_list func.
    """
    norm_cve_lists = [normalize_cve_list(cve_list) for cve_list in cve_lists]

    # Финально удостоверимся что все нормализованные значения будут соответсвуют паттерну CVE
    cve_pattern = re.compile(r"CVE-\d{4}-\d{4,7}")
    bad_cve = [
        cve
        for norm_cve_list in norm_cve_lists
        for cve in norm_cve_list
        if not bool(cve_pattern.fullmatch(cve))
    ]
    if bad_cve:
        # TODO: добавить этот warning в поле error_message таблицы dbupdate_stats
        print(f"WARNING! Detect and not normalized bad CVE patterns: {set(bad_cve)}")

    return norm_cve_lists


def lists_to_strings(list_of_lists, sep=";"):
    """Convert list of lists to list of strings.
    Limitations: all elements must be str
    """
    return [sep.join(row) for row in list_of_lists]


def processing_raw_exploits(exploits_raw_list):
    """Processing raw data exploits and return data, ready to
    write to internal db."""

    exploits_dict = {
        "id": [],
        "type": [],
        "published": [],
        "modified": [],
        "title": [],
        "cvelist": [],
        "cvelist_norm": [],
        "href": [],
    }

    for item in exploits_raw_list:
        for key in exploits_dict:
            if key in item["_source"]:
                exploits_dict[key].append(item["_source"][key])
            else:
                exploits_dict[key].append(None)

    exploits_dict["cvelist_norm"] = normalize_cve_list_of_lists(exploits_dict["cvelist"])

    # convert arrays (lists) to strings with separator to store in sqlite db
    exploits_dict["cvelist"] = lists_to_strings(exploits_dict["cvelist"])
    exploits_dict["cvelist_norm"] = lists_to_strings(exploits_dict["cvelist_norm"])

    return exploits_dict


def get_cve_exploits_matching(exploit_ids: list, cvelist_norms: list, sep=";"):
    """Get tuples (cve_id, exploit_id) for insert into cve_exploit table.

    exploit_ids: list of exploit_id
        (ex. ["exp1", "exp2", "exp3"]),
    cvelist_norms: list of strings with cves separated by sep
        (ex. ["cve1", "cve2;cve3", ""])

    Returns: list of tuples
        (ex. [('cve1', 'exp1'), ('cve2', 'exp2'), ('cve3', 'exp2')])
    """
    assert len(exploit_ids) == len(cvelist_norms)
    return [
        (cve_id, exp_id)
        for exp_id, cvelist in zip(exploit_ids, cvelist_norms)
        for cve_id in cvelist.split(sep)
        if cvelist
    ]


def get_exploit_write_sql_query(exploits_dict):
    sql_query = (
        """
    INSERT OR REPLACE INTO exploit
        (exploit_id, exploit_type, exploit_published, exploit_modified,
         exploit_title, exploit_cvelist_orig, exploit_cvelist_norm, href)
    VALUES (?,?,?,?,?,?,?,?);
    """,
        list(zip(*exploits_dict.values())),
    )

    return sql_query


def get_cve_exploit_write_sql_query(exploits_dict):
    to_cve_exploits = get_cve_exploits_matching(exploits_dict["id"], exploits_dict["cvelist_norm"])

    sql_query = (
        """
    INSERT OR IGNORE INTO cve_exploit (cve_id, exploit_id)
    VALUES (?,?);
    """,
        to_cve_exploits,
    )

    return sql_query


def nvd_api_request(*args, **kwargs):
    """Request to nvd.nist.gov api with check for correct response.
    Raise exceptions for bad responses."""

    req = requests.get(*args, **kwargs)

    if req.status_code != requests.codes.ok:
        raise Exception(f"Bad api status code: {req.status_code}")

    if "vulnerabilities" not in req.json():
        raise Exception(f"Bad api result: {req.json()}")

    return req


def get_raw_cve_updates_from_api(cve_last_db_modified, max_records_threashold=0):
    """Getting the latest updates from api on cve, returns raw
    data without processing.

    cve_last_db_modified (datetime): date of last update of cve
        in the database
    max_records_threashold (positive int or 0 for no limit): the threshold
        for the maximum number of records from the api

    Returns: list of cve dicts.

    """

    # API docs: https://nvd.nist.gov/developers/vulnerabilities
    URL_NVD_CVES_API = "https://services.nvd.nist.gov/rest/json/cves/2.0/?"
    NVD_API_DATE_FORMAT = "%Y-%m-%dT%H:%M:%S"

    # consciously pump out with a margin (1-2 pcs.)
    query = "lastModStartDate={}&lastModEndDate={}&noRejected".format(
        cve_last_db_modified.strftime(NVD_API_DATE_FORMAT),
        (datetime.now() - timedelta(seconds=10)).strftime(NVD_API_DATE_FORMAT),
    )

    cve_raw_list = []
    total_results = None
    per_page = None
    skip = 0

    while per_page is None or skip < total_results:
        req_json = nvd_api_request(f"{URL_NVD_CVES_API}{query}&startIndex={skip}").json()

        # only for first request
        if total_results is None:
            total_results = req_json["totalResults"]
            print("Getting records from vulners api:", end="")

        # number of records given (no more than the default limit of 2000)
        per_page = int(req_json["resultsPerPage"])

        cve_raw_list.extend(req_json["vulnerabilities"])

        print(f" +{len(req_json['vulnerabilities'])}", end="")

        if max_records_threashold and len(cve_raw_list) > max_records_threashold:
            raise Exception(f"Attempt to download too many records: {len(cve_raw_list)}")

        skip += per_page
        sleep(3)

    if len(cve_raw_list) != total_results:
        raise Exception(
            f"Wrong number of cve downloaded {len(cve_raw_list)}, total {total_results}"
        )

    del req_json

    print(f"\nSuccessful downloaded: {len(cve_raw_list)} cve.")

    return cve_raw_list


def get_cve_fields(cve_raw_list, field_name):
    if field_name in [
        "id",
        "published",
        "lastModified",
        "vulnStatus",
        "sourceIdentifier",
    ]:
        return [
            item["cve"][field_name] if field_name in item["cve"] else None for item in cve_raw_list
        ]

    elif field_name == "descriptions":
        result = []
        for item in cve_raw_list:
            for lang in item["cve"]["descriptions"]:
                if lang["lang"] == "en":
                    result.append(lang["value"])
                    break
        return result

    elif field_name[:7] == "cvssv3_":
        result = []
        for item in cve_raw_list:
            metricsV3x = [v for v in item["cve"]["metrics"].keys() if "V3" in v]
            if metricsV3x:
                max_cvssV3_item = item["cve"]["metrics"][max(metricsV3x)][0]
                if field_name[7:] in max_cvssV3_item:
                    result.append(max_cvssV3_item[field_name[7:]])
                else:
                    result.append(max_cvssV3_item["cvssData"][field_name[7:]])
            else:
                result.append(None)
        return result

    elif field_name == "cve_raw_json":
        # json with removed a lot of space fields: 'configurations', 'references'
        # Pay Attention: fields removed also from original cve_raw_list
        result = []
        for item in cve_raw_list:
            for key in ["configurations", "references"]:
                if key in item["cve"]:
                    del item["cve"][key]
            result.append(json.dumps(item["cve"]))
        return result


def processing_raw_cve(cve_raw_list):
    """Processing raw data exploits and return data, ready to
    write to internal db."""

    cve_dict = {
        "id": [],
        "published": [],
        "lastModified": [],
        "descriptions": [],
        "vulnStatus": [],
        "sourceIdentifier": [],
        "cvssv3_vectorString": [],
        "cvssv3_baseScore": [],
        "cvssv3_exploitabilityScore": [],
        "cvssv3_impactScore": [],
        "cve_raw_json": [],
    }

    for field_name in cve_dict:
        cve_dict[field_name] = get_cve_fields(cve_raw_list, field_name)

    return cve_dict


def get_cve_write_sql_query_update(cve_dict):
    sql_query = (
        """
    UPDATE cve
    SET
        cve_published  = :published,
        cve_lastModified  = :lastModified,
        cve_description  = :descriptions,
        cve_vulnStatus  = :vulnStatus,
        cve_sourceIdentifier  = :sourceIdentifier,
        cvssv3_vectorString  = :cvssv3_vectorString,
        cvssv3_baseScore  = :cvssv3_baseScore,
        cvssv3_exploitabilityScore  = :cvssv3_exploitabilityScore,
        cvssv3_impactScore  = :cvssv3_impactScore,
        cve_raw_json  = :cve_raw_json
    WHERE cve_id = :id AND frozen_mode_date IS Null;
    """,
        # needed named style placeholder --> dict of lists to list of dicts
        [dict(zip(cve_dict, vals)) for vals in zip(*cve_dict.values())],
    )

    return sql_query


def get_cve_write_sql_query_insert(cve_dict):
    sql_query = (
        """
    INSERT OR IGNORE INTO cve
        (cve_id, cve_published, cve_lastModified, cve_description, cve_vulnStatus,
        cve_sourceIdentifier, cvssv3_vectorString, cvssv3_baseScore,
        cvssv3_exploitabilityScore, cvssv3_impactScore, cve_raw_json)
    VALUES (?,?,?,?,?,?,?,?,?,?,?);
    """,
        list(zip(*cve_dict.values())),
    )

    return sql_query


def get_cve_write_sql_query_frozen():
    # set frozen mode if all needen for prediction field not null
    # for current model cvssV3 needed
    sql_query = (
        """
    UPDATE cve
    SET
        frozen_mode_date  = datetime('now')
    WHERE cvssv3_vectorString is not Null;
    """,
        None,
    )

    return sql_query


def expoits_update_pipeline(db, stats):
    exp_last_db_modified = get_last_modified_from_db(db, "exploit")
    exploits_raw_list = get_raw_exploit_updates_from_api(exp_last_db_modified)
    exploits_dict = processing_raw_exploits(exploits_raw_list)

    db.to_transaction_queue(*get_exploit_write_sql_query(exploits_dict))
    db.to_transaction_queue(*get_cve_exploit_write_sql_query(exploits_dict))
    
    stats.set_api_stats_exploits(exploits_dict, None)

    return db, stats


def cve_update_pipeline(db, stats):
    cve_last_db_modified = get_last_modified_from_db(db, "cve")
    cve_raw_list = get_raw_cve_updates_from_api(cve_last_db_modified)
    cve_dict = processing_raw_cve(cve_raw_list)

    db.to_transaction_queue(*get_cve_write_sql_query_update(cve_dict))
    db.to_transaction_queue(*get_cve_write_sql_query_insert(cve_dict))
    db.to_transaction_queue(*get_cve_write_sql_query_frozen())

    stats.set_api_stats_cve(cve_dict, None)

    return db, stats


def dbupdate_full_pipeline():
    
    db = InternalDB()
    stats = RunStatsDBUpdate()
    stats.set_db_stats_before(db)

    db, stats = expoits_update_pipeline(db, stats)
    db, stats = cve_update_pipeline(db, stats)

    db.to_transaction_queue(*stats.get_dbupdate_stats_write_sql_query())

    # execute final sql transaction
    db.execute_transaction_queue(verbose=True)

    # push db to remote server
    db.db_push()
    
    stats.set_db_stats_after(db)
    stats.write_final_log()

if __name__ == "__main__":
    dbupdate_full_pipeline()